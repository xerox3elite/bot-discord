"""
üîç ARSENAL COMMAND SCANNER V1.0
Scanner complet et approfondi des commandes

Analyse d√©taill√©e 5 fois comme demand√© :
1. Scan des noms de commandes
2. Scan approfondi du contenu  
3. D√©tection doublons/bugs/indentation
4. Analyse de coh√©rence
5. Rapport final complet

Author: Arsenal Bot Team
Version: 1.0.0
"""

import os
import ast
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple, Any
from collections import defaultdict, Counter
import json

class CommandScanner:
    """Scanner complet des commandes Arsenal"""
    
    def __init__(self, commands_dir: str = "a:/Arsenal_propre/commands"):
        self.commands_dir = Path(commands_dir)
        self.scan_results = {
            'scan_1_names': {},
            'scan_2_content': {},  
            'scan_3_issues': {},
            'scan_4_consistency': {},
            'scan_5_final': {}
        }
        
    def run_complete_analysis(self):
        """Lance l'analyse compl√®te en 5 passes"""
        print("üîç ARSENAL COMMAND SCANNER - ANALYSE COMPL√àTE")
        print("=" * 60)
        
        # SCAN 1: Noms des commandes
        print("\nüìã SCAN 1/5: Analyse des noms de commandes...")
        self.scan_1_command_names()
        
        # SCAN 2: Contenu approfondi
        print("\nüîç SCAN 2/5: Analyse approfondie du contenu...")
        self.scan_2_deep_content_analysis()
        
        # SCAN 3: D√©tection des probl√®mes
        print("\nüö® SCAN 3/5: D√©tection doublons/bugs/indentation...")
        self.scan_3_detect_issues()
        
        # SCAN 4: Coh√©rence g√©n√©rale
        print("\n‚öñÔ∏è SCAN 4/5: Analyse de coh√©rence...")
        self.scan_4_consistency_check()
        
        # SCAN 5: Rapport final
        print("\nüìä SCAN 5/5: G√©n√©ration du rapport final...")
        self.scan_5_final_report()
        
        # Sauvegarder les r√©sultats
        self.save_results()
        
        print("\n‚úÖ ANALYSE COMPL√àTE TERMIN√âE!")
        return self.scan_results
    
    def scan_1_command_names(self):
        """SCAN 1: Analyse des noms de commandes"""
        results = {
            'files_scanned': 0,
            'commands_found': {},
            'app_commands': {},
            'traditional_commands': {},
            'duplicates': [],
            'naming_issues': []
        }
        
        command_names = defaultdict(list)
        
        for py_file in self.commands_dir.glob("*.py"):
            if py_file.name.startswith('__'):
                continue
                
            results['files_scanned'] += 1
            file_commands = self.extract_commands_from_file(py_file)
            
            results['commands_found'][py_file.name] = file_commands
            
            # Compter les occurrences de chaque nom
            for cmd_type, commands in file_commands.items():
                for cmd in commands:
                    command_names[cmd['name']].append({
                        'file': py_file.name,
                        'type': cmd_type,
                        'line': cmd.get('line', 0)
                    })
        
        # D√©tecter les doublons
        for cmd_name, occurrences in command_names.items():
            if len(occurrences) > 1:
                results['duplicates'].append({
                    'command': cmd_name,
                    'occurrences': occurrences
                })
        
        # Analyser les probl√®mes de nommage
        for cmd_name in command_names.keys():
            issues = []
            
            # V√©rifier la convention de nommage
            if not cmd_name.islower():
                issues.append("Not lowercase")
            if ' ' in cmd_name:
                issues.append("Contains spaces")
            if len(cmd_name) > 20:
                issues.append("Too long (>20 chars)")
            if len(cmd_name) < 3:
                issues.append("Too short (<3 chars)")
            
            if issues:
                results['naming_issues'].append({
                    'command': cmd_name,
                    'issues': issues
                })
        
        self.scan_results['scan_1_names'] = results
        print(f"   üìù Fichiers scann√©s: {results['files_scanned']}")
        print(f"   üéØ Commandes trouv√©es: {len(command_names)}")
        print(f"   ‚ö†Ô∏è Doublons d√©tect√©s: {len(results['duplicates'])}")
    
    def scan_2_deep_content_analysis(self):
        """SCAN 2: Analyse approfondie du contenu"""
        results = {
            'complexity_analysis': {},
            'function_analysis': {},
            'import_analysis': {},
            'docstring_analysis': {},
            'code_quality': {}
        }
        
        for py_file in self.commands_dir.glob("*.py"):
            if py_file.name.startswith('__'):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                file_analysis = self.analyze_file_content(py_file.name, content)
                
                results['complexity_analysis'][py_file.name] = file_analysis['complexity']
                results['function_analysis'][py_file.name] = file_analysis['functions']
                results['import_analysis'][py_file.name] = file_analysis['imports']
                results['docstring_analysis'][py_file.name] = file_analysis['docstrings']
                results['code_quality'][py_file.name] = file_analysis['quality']
                
            except Exception as e:
                print(f"   ‚ùå Erreur analyse {py_file.name}: {e}")
        
        self.scan_results['scan_2_content'] = results
        print(f"   üî¨ Analyse complexit√©: {len(results['complexity_analysis'])} fichiers")
        print(f"   üìä Analyse fonctions: {len(results['function_analysis'])} fichiers")
    
    def scan_3_detect_issues(self):
        """SCAN 3: D√©tection des probl√®mes (doublons/bugs/indentation)"""
        results = {
            'duplicate_functions': [],
            'indentation_issues': [],
            'syntax_errors': [],
            'potential_bugs': [],
            'unused_imports': [],
            'long_functions': []
        }
        
        all_functions = defaultdict(list)
        
        for py_file in self.commands_dir.glob("*.py"):
            if py_file.name.startswith('__'):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                
                # Analyser l'indentation
                indentation_issues = self.check_indentation_issues(lines, py_file.name)
                results['indentation_issues'].extend(indentation_issues)
                
                # D√©tecter les erreurs de syntaxe potentielles
                syntax_issues = self.check_syntax_issues(content, py_file.name)
                results['syntax_errors'].extend(syntax_issues)
                
                # Analyser l'AST pour les bugs potentiels
                try:
                    tree = ast.parse(content)
                    
                    # Collecter les fonctions
                    for node in ast.walk(tree):
                        if isinstance(node, ast.FunctionDef):
                            func_signature = f"{node.name}({len(node.args.args)})"
                            all_functions[func_signature].append({
                                'file': py_file.name,
                                'name': node.name,
                                'line': node.lineno,
                                'length': self.count_function_lines(node, lines)
                            })
                    
                    # D√©tecter les bugs potentiels
                    bugs = self.detect_potential_bugs(tree, py_file.name)
                    results['potential_bugs'].extend(bugs)
                    
                except SyntaxError as e:
                    results['syntax_errors'].append({
                        'file': py_file.name,
                        'error': str(e),
                        'line': e.lineno
                    })
                
            except Exception as e:
                print(f"   ‚ùå Erreur scan probl√®mes {py_file.name}: {e}")
        
        # D√©tecter les fonctions dupliqu√©es
        for func_sig, occurrences in all_functions.items():
            if len(occurrences) > 1:
                # V√©rifier si c'est vraiment un doublon (m√™me contenu)
                potential_duplicate = True
                if potential_duplicate:
                    results['duplicate_functions'].append({
                        'signature': func_sig,
                        'occurrences': occurrences
                    })
        
        # D√©tecter les fonctions trop longues
        for occurrences in all_functions.values():
            for func in occurrences:
                if func['length'] > 100:  # Plus de 100 lignes
                    results['long_functions'].append(func)
        
        self.scan_results['scan_3_issues'] = results
        print(f"   üîÑ Fonctions dupliqu√©es: {len(results['duplicate_functions'])}")
        print(f"   üìê Probl√®mes indentation: {len(results['indentation_issues'])}")
        print(f"   üêõ Bugs potentiels: {len(results['potential_bugs'])}")
    
    def scan_4_consistency_check(self):
        """SCAN 4: V√©rification de coh√©rence"""
        results = {
            'naming_consistency': {},
            'structure_consistency': {},
            'import_consistency': {},
            'documentation_consistency': {},
            'style_consistency': {}
        }
        
        # Analyser la coh√©rence des noms
        all_patterns = {
            'class_names': [],
            'function_names': [],
            'variable_names': [],
            'constant_names': []
        }
        
        for py_file in self.commands_dir.glob("*.py"):
            if py_file.name.startswith('__'):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                
                # Collecter les patterns de nommage
                for node in ast.walk(tree):
                    if isinstance(node, ast.ClassDef):
                        all_patterns['class_names'].append(node.name)
                    elif isinstance(node, ast.FunctionDef):
                        all_patterns['function_names'].append(node.name)
                    elif isinstance(node, ast.Assign):
                        for target in node.targets:
                            if isinstance(target, ast.Name):
                                if target.id.isupper():
                                    all_patterns['constant_names'].append(target.id)
                                else:
                                    all_patterns['variable_names'].append(target.id)
                
            except Exception as e:
                print(f"   ‚ùå Erreur coh√©rence {py_file.name}: {e}")
        
        # Analyser les patterns
        for pattern_type, names in all_patterns.items():
            consistency_score = self.calculate_naming_consistency(names)
            results['naming_consistency'][pattern_type] = {
                'total': len(names),
                'consistency_score': consistency_score,
                'common_patterns': Counter([self.extract_naming_pattern(name) for name in names]).most_common(5)
            }
        
        self.scan_results['scan_4_consistency'] = results
        print(f"   ‚úÖ Coh√©rence classes: {results['naming_consistency']['class_names']['consistency_score']:.2f}")
        print(f"   ‚úÖ Coh√©rence fonctions: {results['naming_consistency']['function_names']['consistency_score']:.2f}")
    
    def scan_5_final_report(self):
        """SCAN 5: G√©n√©ration du rapport final"""
        results = {
            'summary': {},
            'critical_issues': [],
            'recommendations': [],
            'statistics': {},
            'quality_score': 0
        }
        
        # R√©sum√© des scans pr√©c√©dents
        results['summary'] = {
            'total_files': self.scan_results['scan_1_names']['files_scanned'],
            'total_commands': len(self.scan_results['scan_1_names']['commands_found']),
            'duplicate_commands': len(self.scan_results['scan_1_names']['duplicates']),
            'syntax_errors': len(self.scan_results['scan_3_issues']['syntax_errors']),
            'potential_bugs': len(self.scan_results['scan_3_issues']['potential_bugs']),
            'indentation_issues': len(self.scan_results['scan_3_issues']['indentation_issues'])
        }
        
        # Issues critiques
        critical_count = 0
        
        # Erreurs de syntaxe (critique)
        if self.scan_results['scan_3_issues']['syntax_errors']:
            results['critical_issues'].append({
                'type': 'CRITIQUE: Erreurs de syntaxe',
                'count': len(self.scan_results['scan_3_issues']['syntax_errors']),
                'details': self.scan_results['scan_3_issues']['syntax_errors']
            })
            critical_count += len(self.scan_results['scan_3_issues']['syntax_errors']) * 10
        
        # Doublons de commandes (important)
        if self.scan_results['scan_1_names']['duplicates']:
            results['critical_issues'].append({
                'type': 'IMPORTANT: Commandes dupliqu√©es',
                'count': len(self.scan_results['scan_1_names']['duplicates']),
                'details': self.scan_results['scan_1_names']['duplicates']
            })
            critical_count += len(self.scan_results['scan_1_names']['duplicates']) * 5
        
        # Bugs potentiels (important)
        if self.scan_results['scan_3_issues']['potential_bugs']:
            results['critical_issues'].append({
                'type': 'IMPORTANT: Bugs potentiels',
                'count': len(self.scan_results['scan_3_issues']['potential_bugs']),
                'details': self.scan_results['scan_3_issues']['potential_bugs']
            })
            critical_count += len(self.scan_results['scan_3_issues']['potential_bugs']) * 3
        
        # Calculer le score de qualit√© (0-100)
        base_score = 100
        quality_score = max(0, base_score - critical_count)
        results['quality_score'] = quality_score
        
        # G√©n√©rer des recommandations
        recommendations = []
        
        if self.scan_results['scan_3_issues']['syntax_errors']:
            recommendations.append("üî¥ URGENT: Corriger les erreurs de syntaxe")
        
        if self.scan_results['scan_1_names']['duplicates']:
            recommendations.append("üü† IMPORTANT: Renommer ou fusionner les commandes dupliqu√©es")
        
        if self.scan_results['scan_3_issues']['indentation_issues']:
            recommendations.append("üü° Corriger les probl√®mes d'indentation")
        
        if self.scan_results['scan_3_issues']['long_functions']:
            recommendations.append("üü° Diviser les fonctions trop longues (>100 lignes)")
        
        if quality_score > 80:
            recommendations.append("‚úÖ Code en bon √©tat g√©n√©ral")
        elif quality_score > 60:
            recommendations.append("‚ö†Ô∏è Code n√©cessite des am√©liorations")
        else:
            recommendations.append("üö® Code n√©cessite une r√©vision majeure")
        
        results['recommendations'] = recommendations
        
        self.scan_results['scan_5_final'] = results
        print(f"   üìä Score qualit√©: {quality_score}/100")
        print(f"   ‚ö†Ô∏è Issues critiques: {len(results['critical_issues'])}")
        print(f"   üí° Recommandations: {len(recommendations)}")
    
    # M√©thodes utilitaires
    def extract_commands_from_file(self, file_path: Path) -> Dict[str, List]:
        """Extrait toutes les commandes d'un fichier"""
        commands = {
            'app_commands': [],
            'traditional_commands': [],
            'groups': []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Chercher les app_commands
            app_cmd_pattern = r'@app_commands\.command\(name=["\']([^"\']+)["\']'
            for match in re.finditer(app_cmd_pattern, content):
                line_num = content[:match.start()].count('\n') + 1
                commands['app_commands'].append({
                    'name': match.group(1),
                    'line': line_num
                })
            
            # Chercher les commandes traditionnelles
            trad_cmd_pattern = r'@commands\.command\(name=["\']([^"\']+)["\']'
            for match in re.finditer(trad_cmd_pattern, content):
                line_num = content[:match.start()].count('\n') + 1
                commands['traditional_commands'].append({
                    'name': match.group(1),
                    'line': line_num
                })
            
            # Chercher aussi les d√©corateurs simples
            simple_pattern = r'@commands\.command\(\s*\)\s*async def ([a-zA-Z_][a-zA-Z0-9_]*)'
            for match in re.finditer(simple_pattern, content):
                line_num = content[:match.start()].count('\n') + 1
                commands['traditional_commands'].append({
                    'name': match.group(1),
                    'line': line_num
                })
                
        except Exception as e:
            print(f"   ‚ùå Erreur extraction {file_path.name}: {e}")
        
        return commands
    
    def analyze_file_content(self, filename: str, content: str) -> Dict[str, Any]:
        """Analyse le contenu d'un fichier"""
        analysis = {
            'complexity': {},
            'functions': {},
            'imports': {},
            'docstrings': {},
            'quality': {}
        }
        
        lines = content.split('\n')
        
        # Analyse de complexit√©
        analysis['complexity'] = {
            'total_lines': len(lines),
            'code_lines': len([l for l in lines if l.strip() and not l.strip().startswith('#')]),
            'comment_lines': len([l for l in lines if l.strip().startswith('#')]),
            'blank_lines': len([l for l in lines if not l.strip()])
        }
        
        # Analyse des imports
        imports = []
        for i, line in enumerate(lines, 1):
            if line.strip().startswith('import ') or line.strip().startswith('from '):
                imports.append({'line': i, 'import': line.strip()})
        
        analysis['imports'] = {
            'total': len(imports),
            'details': imports
        }
        
        # Analyse des docstrings
        docstring_count = content.count('"""') + content.count("'''")
        analysis['docstrings'] = {
            'count': docstring_count // 2,  # Paires ouverture/fermeture
            'has_module_docstring': content.strip().startswith('"""') or content.strip().startswith("'''")
        }
        
        return analysis
    
    def check_indentation_issues(self, lines: List[str], filename: str) -> List[Dict]:
        """V√©rifie les probl√®mes d'indentation"""
        issues = []
        
        for i, line in enumerate(lines, 1):
            if not line.strip():
                continue
                
            # V√©rifier l'indentation (espaces vs tabs)
            leading = line[:len(line) - len(line.lstrip())]
            
            if '\t' in leading and ' ' in leading:
                issues.append({
                    'file': filename,
                    'line': i,
                    'issue': 'Mixed tabs and spaces',
                    'content': line.strip()
                })
        
        return issues
    
    def check_syntax_issues(self, content: str, filename: str) -> List[Dict]:
        """V√©rifie les erreurs de syntaxe potentielles"""
        issues = []
        
        # V√©rifications basiques
        lines = content.split('\n')
        
        for i, line in enumerate(lines, 1):
            stripped = line.strip()
            
            # Parenth√®ses non ferm√©es
            if stripped.count('(') != stripped.count(')'):
                if not stripped.endswith('\\'):  # Continuation de ligne
                    issues.append({
                        'file': filename,
                        'line': i,
                        'issue': 'Unmatched parentheses',
                        'content': stripped
                    })
        
        return issues
    
    def detect_potential_bugs(self, tree: ast.AST, filename: str) -> List[Dict]:
        """D√©tecte les bugs potentiels via AST"""
        bugs = []
        
        for node in ast.walk(tree):
            # Variables non utilis√©es (approximation)
            if isinstance(node, ast.Assign):
                # Logique de d√©tection simplifi√©e
                pass
                
            # Imports non utilis√©s (approximation)  
            if isinstance(node, ast.Import):
                # Logique de d√©tection simplifi√©e
                pass
        
        return bugs
    
    def count_function_lines(self, func_node: ast.FunctionDef, lines: List[str]) -> int:
        """Compte les lignes d'une fonction"""
        start_line = func_node.lineno - 1
        
        # Trouver la fin de la fonction (approximation)
        end_line = start_line + 1
        indent_level = None
        
        for i in range(start_line + 1, len(lines)):
            line = lines[i]
            if not line.strip():
                continue
                
            current_indent = len(line) - len(line.lstrip())
            
            if indent_level is None:
                indent_level = current_indent
            elif current_indent <= len(lines[start_line]) - len(lines[start_line].lstrip()) and line.strip():
                break
                
            end_line = i
        
        return end_line - start_line + 1
    
    def calculate_naming_consistency(self, names: List[str]) -> float:
        """Calcule le score de coh√©rence des noms"""
        if not names:
            return 1.0
        
        # Analyser les patterns de nommage
        patterns = [self.extract_naming_pattern(name) for name in names]
        pattern_counts = Counter(patterns)
        
        # Le pattern le plus fr√©quent
        most_common = pattern_counts.most_common(1)[0][1] if pattern_counts else 0
        
        return most_common / len(names) if names else 1.0
    
    def extract_naming_pattern(self, name: str) -> str:
        """Extrait le pattern de nommage d'un nom"""
        if '_' in name:
            return 'snake_case'
        elif name.islower():
            return 'lowercase'
        elif name.isupper():
            return 'UPPERCASE'
        elif name[0].isupper():
            return 'CamelCase'
        else:
            return 'mixed'
    
    def save_results(self):
        """Sauvegarde les r√©sultats dans un fichier"""
        output_file = self.commands_dir.parent / "command_scan_results.json"
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.scan_results, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"\nüíæ R√©sultats sauvegard√©s dans: {output_file}")
            
        except Exception as e:
            print(f"‚ùå Erreur sauvegarde: {e}")
    
    def print_detailed_report(self):
        """Affiche le rapport d√©taill√©"""
        print("\n" + "="*80)
        print("üìä RAPPORT D√âTAILL√â - ANALYSE COMPL√àTE DES COMMANDES")
        print("="*80)
        
        final_results = self.scan_results['scan_5_final']
        
        # R√©sum√©
        print(f"\nüìã R√âSUM√â G√âN√âRAL:")
        summary = final_results['summary']
        print(f"   ‚Ä¢ Fichiers scann√©s: {summary['total_files']}")
        print(f"   ‚Ä¢ Commandes trouv√©es: {summary['total_commands']}")
        print(f"   ‚Ä¢ Commandes dupliqu√©es: {summary['duplicate_commands']}")
        print(f"   ‚Ä¢ Erreurs de syntaxe: {summary['syntax_errors']}")
        print(f"   ‚Ä¢ Bugs potentiels: {summary['potential_bugs']}")
        print(f"   ‚Ä¢ Probl√®mes indentation: {summary['indentation_issues']}")
        
        # Score de qualit√©
        print(f"\nüìä SCORE DE QUALIT√â: {final_results['quality_score']}/100")
        if final_results['quality_score'] >= 80:
            print("   ‚úÖ EXCELLENT - Code de haute qualit√©")
        elif final_results['quality_score'] >= 60:
            print("   ‚ö†Ô∏è MOYEN - Am√©liorations recommand√©es")
        else:
            print("   üö® FAIBLE - R√©vision majeure n√©cessaire")
        
        # Issues critiques
        if final_results['critical_issues']:
            print(f"\nüö® ISSUES CRITIQUES ({len(final_results['critical_issues'])}):")
            for issue in final_results['critical_issues']:
                print(f"   ‚Ä¢ {issue['type']}: {issue['count']} occurrences")
        
        # Recommandations
        print(f"\nüí° RECOMMANDATIONS ({len(final_results['recommendations'])}):")
        for i, rec in enumerate(final_results['recommendations'], 1):
            print(f"   {i}. {rec}")
        
        # D√©tails des doublons si pr√©sents
        duplicates = self.scan_results['scan_1_names']['duplicates']
        if duplicates:
            print(f"\nüîÑ COMMANDES DUPLIQU√âES ({len(duplicates)}):")
            for dup in duplicates:
                print(f"   ‚Ä¢ '{dup['command']}' trouv√©e dans:")
                for occ in dup['occurrences']:
                    print(f"     - {occ['file']} (ligne {occ['line']}, type: {occ['type']})")
        
        print("\n" + "="*80)
        print("‚úÖ ANALYSE TERMIN√âE - Consultez command_scan_results.json pour les d√©tails complets")
        print("="*80)

# Lancer le scan
if __name__ == "__main__":
    scanner = CommandScanner()
    results = scanner.run_complete_analysis()
    scanner.print_detailed_report()

